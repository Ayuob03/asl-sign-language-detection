# ðŸ–ï¸ American Sign Language Letter Detection (YOLOv8)

This project uses **YOLOv8** to detect **American Sign Language (ASL) hand gestures** and classify each one as a letter (Aâ€“Z).  
It was trained using a labeled dataset from Roboflow, where each hand sign is annotated with a bounding box and class label.

---

## ðŸŽ¯ Project Goal

To build a computer vision model that can:

- Detect the hand in an image ðŸ“¸  
- Draw a bounding box around it â¬›  
- Predict the corresponding ASL letter ðŸ”¤  

This type of system can support:

- assistive communication tools  
- sign-language education apps  
- gesture-based interfaces  

---

## ðŸ§  Model

We used:

- **Model:** YOLOv8 (Nano)  
- **Framework:** Ultralytics  
- **Training:** Transfer learning (fine-tuned on ASL dataset)

YOLO was chosen because it is:

âœ” fast  
âœ” accurate  
âœ” easy to deploy  

---

## ðŸ“¦ Dataset

Dataset source:

> **American Sign Language Letters â€” Object Detection**  
Provided by Roboflow Universe.

Each image contains:

- a hand showing a gesture  
- a bounding box  
- a label (A, B, C, â€¦)

The dataset was automatically downloaded in Colab using the Roboflow API and exported in **YOLOv8 format**.

---

## ðŸš€ How to Train

Install dependencies:

```bash
pip install ultralytics roboflow
